{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GT 650M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Dropout, Activation, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist, cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 49  # Generator complexity\n",
    "g_output_size = 100    # size of generated output vector\n",
    "\n",
    "d_input_size = 100  # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "num_epochs = 50000\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameter settings\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "nb_filters = 32\n",
    "nb_pool = 2\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "#     return lambda n : K.random_normal(mean=mu, std=sigma, shape=(1, n))\n",
    "    return lambda m, n : np.random.normal(mu, sigma, size=(m, n)).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generator_input_sampler():\n",
    "#     return lambda m, n: K.random_uniform(shape=(m, n))\n",
    "    return lambda m, n: np.random.rand(m, n).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#samplers for data distribution\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(hidden_size, input_shape = (input_size,), activation = \"elu\"))\n",
    "        self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "#         self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "#         self.model.add(Dense(output_size, activation = \"linear\"))\n",
    "        self.model.add(Reshape((1, 7, 7)))\n",
    "#         self.model.add(UpSampling2D(size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                              activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                      activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "#         self.model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "#               activation=\"elu\", data_format=\"channels_first\"))\n",
    "#         self.model.add(Dropout(0.5))\n",
    "        self.model.add(UpSampling2D(size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "          activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "          activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                              activation=\"sigmoid\", data_format=\"channels_first\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = Sequential()\n",
    "#         self.model.add(Dense(hidden_size, input_shape = (input_size,), activation = \"elu\"))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", use_bias=True,\n",
    "                                     input_shape=(1, img_rows, img_cols), activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                     activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", use_bias=True,\n",
    "                                     activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                     activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "        self.model.add(Dense(output_size, activation = \"sigmoid\"))\n",
    "    \n",
    "    def compileModel(**kwargs):\n",
    "        self.model.compile(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneratorAndDiscriminator:\n",
    "    \n",
    "    def __init__(self, generator, discriminator):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(generator)\n",
    "        \n",
    "        discriminator.trainable = False\n",
    "        self.model.add(discriminator)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_progress(epoch, epochs, start_time):\n",
    "    \n",
    "    bar_length = 50\n",
    "    \n",
    "    progress_bar = \"[\" + \"=\" * int(bar_length * epoch / epochs) + \\\n",
    "    \">\" + \"-\" * int(bar_length * (epochs - epoch) / epochs) + \"]\"\n",
    "    \n",
    "    time_taken = (time() - start_time)\n",
    "    \n",
    "    secs = np.ceil(time_taken * epochs / epoch - time_taken)\n",
    "    hours = np.floor(secs / 3600)\n",
    "    secs -= hours * 3600\n",
    "    mins = np.floor(secs / 60)\n",
    "    secs -= mins * 60\n",
    "    \n",
    "    sys.stdout.write(\"\\r\" + \"Epoch {}/{} \".format(epoch, epochs) + progress_bar + \n",
    "                     \" {}% ETA: {}h {}m {}s\".format(int(epoch * 100 / epochs), int(hours), int(mins), int(secs)) + \n",
    "                     \" \" * 10)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#construct discriminator\n",
    "D = Discriminator(d_input_size, d_hidden_size, d_output_size)\n",
    "\n",
    "#compile D\n",
    "D.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#construct generator\n",
    "G = Generator(g_input_size, g_hidden_size, g_output_size)\n",
    "\n",
    "#compile G\n",
    "G.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##generator and discriminator\n",
    "GD = GeneratorAndDiscriminator(G.model, D.model)\n",
    "\n",
    "#compile GD\n",
    "GD.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##load mnist data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "##reshape data\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "num_patterns = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4588/50000 [====>---------------------------------------------] 9% ETA: 1.0h 7.0m 9.0s             "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "'''\n",
    "main loop\n",
    "'''\n",
    "\n",
    "n = 1\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for d_step in range(d_steps):\n",
    "        \n",
    "        #train D on real data\n",
    "#         d_real_data = d_sampler(1, d_input_size)\n",
    "        d_real_data = np.expand_dims(x_train[np.random.randint(num_patterns)], axis=0)\n",
    "#         d_real_data = x_train\n",
    "        d_real_targets = np.ones(n)\n",
    "        \n",
    "        #train D on fake data\n",
    "        d_gen_data = gi_sampler(n, g_input_size)\n",
    "        d_fake_data = G.model.predict(d_gen_data)\n",
    "        d_fake_targets = np.zeros(n)\n",
    "        \n",
    "        d_data = np.append(d_real_data, d_fake_data, axis=0)\n",
    "        d_targets = np.append(d_real_targets, d_fake_targets)\n",
    "\n",
    "        #fit discriminator\n",
    "        D.model.trainable = True\n",
    "        D.model.fit(d_data, d_targets, shuffle=True, epochs=3,\n",
    "              batch_size=1, validation_split=0.0, verbose=0)\n",
    "        \n",
    "    for g_step in range(g_steps):\n",
    "        \n",
    "        #generate data from noise\n",
    "        gen_input = gi_sampler(n, g_input_size)\n",
    "        \n",
    "        #target\n",
    "        target = np.ones(n)\n",
    "        \n",
    "        #fit generator\n",
    "        D.model.trainable = False\n",
    "        GD.model.fit(gen_input, target, shuffle=True, epochs=3,\n",
    "              batch_size=1, validation_split=0.0, verbose=0)\n",
    "        \n",
    "    print_progress(epoch, num_epochs, start_time)\n",
    "\n",
    "print \"\\nDONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 5\n",
    "plt.imshow(x_train[i, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_input = gi_sampler(1, g_input_size)\n",
    "forgery = G.model.predict(gen_input)\n",
    "\n",
    "# print np.mean(forgery)\n",
    "\n",
    "i = 0\n",
    "\n",
    "plt.imshow(forgery[i ,0])\n",
    "plt.show()\n",
    "\n",
    "print D.model.predict(forgery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_real_data = d_sampler(100, d_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.97750616,  5.25092888,  4.59791613, ...,  4.76979065,\n",
       "         4.08094931,  2.61142635],\n",
       "       [ 4.0486145 ,  4.50510311,  4.73263216, ...,  4.83788395,\n",
       "         4.6385498 ,  3.18401814],\n",
       "       [ 4.82702923,  6.47186995,  3.89000297, ...,  3.54565644,\n",
       "         5.12652969,  6.09436893],\n",
       "       ..., \n",
       "       [ 2.72764564,  4.03013802,  1.99318993, ...,  3.19162607,\n",
       "         4.72337151,  2.75904036],\n",
       "       [ 5.90803957,  1.71235585,  3.32587624, ...,  4.61864996,\n",
       "         5.31416559,  5.39929628],\n",
       "       [ 3.58024287,  3.90217638,  2.14244676, ...,  4.64943457,\n",
       "         0.63970524,  1.97230172]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
