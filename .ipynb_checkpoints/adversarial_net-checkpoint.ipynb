{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GT 650M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Dropout, Activation, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist, cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 100     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 196   # Generator complexity\n",
    "g_output_size = 100    # size of generated output vector\n",
    "\n",
    "d_input_size = 100  # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 10000\n",
    "print_interval = 200\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameter settings\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "nb_filters = 32\n",
    "nb_pool = 2\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "#     return lambda n : K.random_normal(mean=mu, std=sigma, shape=(1, n))\n",
    "    return lambda m, n : np.random.normal(mu, sigma, size=(m, n)).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generator_input_sampler():\n",
    "#     return lambda m, n: K.random_uniform(shape=(m, n))\n",
    "    return lambda m, n: np.random.rand(m, n).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#samplers for data distribution\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(hidden_size, input_shape = (input_size,), activation = \"elu\"))\n",
    "        self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "#         self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "#         self.model.add(Dense(output_size, activation = \"linear\"))\n",
    "        self.model.add(Reshape((1, 14, 14)))\n",
    "        self.model.add(UpSampling2D(size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                              activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                      activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                              activation=\"sigmoid\", data_format=\"channels_first\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = Sequential()\n",
    "#         self.model.add(Dense(hidden_size, input_shape = (input_size,), activation = \"elu\"))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", use_bias=True,\n",
    "                                     input_shape=(1, img_rows, img_cols), activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                     activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "        self.model.add(Dense(output_size, activation = \"sigmoid\"))\n",
    "    \n",
    "    def compileModel(**kwargs):\n",
    "        self.model.compile(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneratorAndDiscriminator:\n",
    "    \n",
    "    def __init__(self, generator, discriminator):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(generator)\n",
    "        \n",
    "        discriminator.trainable = False\n",
    "        self.model.add(discriminator)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(epoch, epochs, start_time):\n",
    "    \n",
    "    bar_length = 50\n",
    "    \n",
    "    progress_bar = \"[\" + \"=\" * int(bar_length * epoch / epochs) + \">\" + \"-\" * int(bar_length * (epochs - epoch) / epochs) + \"]\"\n",
    "    \n",
    "    time_taken = (time() - start_time)\n",
    "    \n",
    "    secs = np.ceil(time_taken * epochs / epoch - time_taken)\n",
    "    hours = np.floor(secs / 3600)\n",
    "    secs -= hours * 3600\n",
    "    mins = np.floor(secs / 60)\n",
    "    secs -= mins * 60\n",
    "    \n",
    "    sys.stdout.write(\"\\r\" + progress_bar + \n",
    "                     \" Epoch {}/{} ETA: {}h {}m {}s\".format(epoch, epochs, hours, mins, secs) + \" \" * 10)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#construct discriminator\n",
    "D = Discriminator(d_input_size, d_hidden_size, d_output_size)\n",
    "\n",
    "#compile D\n",
    "D.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#construct generator\n",
    "G = Generator(g_input_size, g_hidden_size, g_output_size)\n",
    "\n",
    "#compile G\n",
    "G.model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##generator and discriminator\n",
    "GD = GeneratorAndDiscriminator(G.model, D.model)\n",
    "\n",
    "#compile GD\n",
    "GD.model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##load mnist data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "##reshape data\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "num_patterns = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "'''\n",
    "main loop\n",
    "'''\n",
    "\n",
    "n = 1\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for d_step in range(d_steps):\n",
    "        \n",
    "        #train D on real data\n",
    "#         d_real_data = d_sampler(1, d_input_size)\n",
    "        d_real_data = np.expand_dims(x_train[np.random.randint(num_patterns)], axis=0)\n",
    "#         d_real_data = x_train\n",
    "        d_real_targets = np.ones(n)\n",
    "        \n",
    "        #train D on fake data\n",
    "        d_gen_data = gi_sampler(n, g_input_size)\n",
    "        d_fake_data = G.model.predict(d_gen_data)\n",
    "        d_fake_targets = np.zeros(n)\n",
    "        \n",
    "        d_data = np.append(d_real_data, d_fake_data, axis=0)\n",
    "        d_targets = np.append(d_real_targets, d_fake_targets)\n",
    "\n",
    "        #fit discriminator\n",
    "        D.model.trainable = True\n",
    "        D.model.fit(d_data, d_targets, shuffle=True, epochs=3,\n",
    "              batch_size=1, validation_split=0.0, verbose=0)\n",
    "        \n",
    "    for g_step in range(g_steps):\n",
    "        \n",
    "        #generate data from noise\n",
    "        gen_input = gi_sampler(n, g_input_size)\n",
    "        \n",
    "        #target\n",
    "        target = np.ones(n)\n",
    "        \n",
    "        #fit generator\n",
    "        D.model.trainable = False\n",
    "        GD.model.fit(gen_input, target, shuffle=True, epochs=3,\n",
    "              batch_size=1, validation_split=0.0, verbose=0)\n",
    "        \n",
    "    print_progress(epoch, num_epochs, start_time)\n",
    "\n",
    "print \"\\nDONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0H9P9F/mcSyc5sfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8a2e3e090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 5\n",
    "plt.imshow(x_train[i, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlIJfJFEKfpFEKfhFEqXgF0mUgl8kUf8HBgg7vqpNEO4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc88de08290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "gen_input = gi_sampler(1000, g_input_size)\n",
    "forgery = G.model.predict(gen_input)\n",
    "\n",
    "# print np.mean(forgery)\n",
    "\n",
    "i = 5\n",
    "\n",
    "plt.imshow(forgery[i ,0])\n",
    "plt.show()\n",
    "\n",
    "print D.model.predict(forgery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_real_data = d_sampler(100, d_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.97750616,  5.25092888,  4.59791613, ...,  4.76979065,\n",
       "         4.08094931,  2.61142635],\n",
       "       [ 4.0486145 ,  4.50510311,  4.73263216, ...,  4.83788395,\n",
       "         4.6385498 ,  3.18401814],\n",
       "       [ 4.82702923,  6.47186995,  3.89000297, ...,  3.54565644,\n",
       "         5.12652969,  6.09436893],\n",
       "       ..., \n",
       "       [ 2.72764564,  4.03013802,  1.99318993, ...,  3.19162607,\n",
       "         4.72337151,  2.75904036],\n",
       "       [ 5.90803957,  1.71235585,  3.32587624, ...,  4.61864996,\n",
       "         5.31416559,  5.39929628],\n",
       "       [ 3.58024287,  3.90217638,  2.14244676, ...,  4.64943457,\n",
       "         0.63970524,  1.97230172]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
