{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 164, in <module>\n",
      "    use(config.device)\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 151, in use\n",
      "    init_dev(device)\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 60, in init_dev\n",
      "    sched=config.gpuarray.sched)\n",
      "  File \"pygpu/gpuarray.pyx\", line 614, in pygpu.gpuarray.init (pygpu/gpuarray.c:9415)\n",
      "  File \"pygpu/gpuarray.pyx\", line 566, in pygpu.gpuarray.pygpu_init (pygpu/gpuarray.c:9106)\n",
      "  File \"pygpu/gpuarray.pyx\", line 1021, in pygpu.gpuarray.GpuContext.__cinit__ (pygpu/gpuarray.c:13468)\n",
      "GpuArrayException: Error loading library: -1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Dropout, Activation, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist, cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 100     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 196   # Generator complexity\n",
    "g_output_size = 100    # size of generated output vector\n",
    "\n",
    "d_input_size = 100  # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 50\n",
    "print_interval = 200\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameter settings\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "nb_filters = 32\n",
    "nb_pool = 2\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "#     return lambda n : K.random_normal(mean=mu, std=sigma, shape=(1, n))\n",
    "    return lambda m, n : np.random.normal(mu, sigma, size=(m, n)).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generator_input_sampler():\n",
    "#     return lambda m, n: K.random_uniform(shape=(m, n))\n",
    "    return lambda m, n: np.random.rand(m, n).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#samplers for data distribution\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(hidden_size, input_shape = (input_size,), activation = \"elu\"))\n",
    "        self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "#         self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "#         self.model.add(Dense(output_size, activation = \"linear\"))\n",
    "        self.model.add(Reshape((1, 14, 14)))\n",
    "        self.model.add(UpSampling2D(size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                              activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", use_bias=True,\n",
    "                              activation=\"elu\", data_format=\"channels_first\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = Sequential()\n",
    "#         self.model.add(Dense(hidden_size, input_shape = (input_size,), activation = \"elu\"))\n",
    "        self.model.add(Conv2D(filters=3, kernel_size=3, strides=1, padding=\"same\", use_bias=True,\n",
    "                                     input_shape=(1, img_rows, img_cols), activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(Conv2D(filters=3, kernel_size=(3, 3),\n",
    "                                     activation=\"elu\", data_format=\"channels_first\"))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(hidden_size, activation = \"elu\"))\n",
    "        self.model.add(Dense(output_size, activation = \"sigmoid\"))\n",
    "    \n",
    "    def compileModel(**kwargs):\n",
    "        self.model.compile(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneratorAndDiscriminator:\n",
    "    \n",
    "    def __init__(self, generator, discriminator):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(generator)\n",
    "        \n",
    "        discriminator.trainable = False\n",
    "        self.model.add(discriminator)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(epoch, epochs, start_time):\n",
    "    \n",
    "    bar_length = 50\n",
    "    \n",
    "    progress_bar = \"[\" + \"=\" * int(bar_length * epoch / epochs) + \">\" + \"-\" * int(bar_length * (epochs - epoch) / epochs) + \"]\"\n",
    "    \n",
    "    time_taken = (time() - start_time)\n",
    "    \n",
    "    secs = np.ceil(time_taken * epochs / epoch - time_taken)\n",
    "    hours = np.floor(secs / 3600)\n",
    "    secs -= hours * 3600\n",
    "    mins = np.floor(secs / 60)\n",
    "    secs -= mins * 60\n",
    "    \n",
    "    sys.stdout.write(\"\\b\" * 200 + progress_bar + \" Epoch {}/{} ETA: {}h {}m {}s\".format(epoch, epochs, hours, mins, secs))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#construct discriminator\n",
    "D = Discriminator(d_input_size, d_hidden_size, d_output_size)\n",
    "\n",
    "#compile D\n",
    "D.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#construct generator\n",
    "G = Generator(g_input_size, g_hidden_size, g_output_size)\n",
    "\n",
    "#compile G\n",
    "G.model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##generator and discriminator\n",
    "\n",
    "GD = GeneratorAndDiscriminator(G.model, D.model)\n",
    "GD.model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "##load mnist data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "##reshape data\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "GpuArrayException",
     "evalue": "('Value invalid or out of range', 2)\nApply node that caused the error: GpuDot22(GpuReshape{2}.0, dense_3/kernel)\nToposort index: 200\nInputs types: [GpuArrayType<None>(float32, (False, False)), GpuArrayType<None>(float32, (False, False))]\nInputs shapes: [(1, 363), (507, 50)]\nInputs strides: [(1452, 4), (200, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Add}[(0, 0)]<gpuarray>(GpuDot22.0, InplaceGpuDimShuffle{x,0}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGpuArrayException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-41971925709f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         GD.model.fit(gen_input, target, shuffle=True, epochs=10,\n\u001b[0;32m---> 45\u001b[0;31m               batch_size=1, validation_split=0.0, verbose=0)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpygpu/blas.pyx\u001b[0m in \u001b[0;36mpygpu.blas.pygpu_blas_rgemm (pygpu/blas.c:2007)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGpuArrayException\u001b[0m: ('Value invalid or out of range', 2)\nApply node that caused the error: GpuDot22(GpuReshape{2}.0, dense_3/kernel)\nToposort index: 200\nInputs types: [GpuArrayType<None>(float32, (False, False)), GpuArrayType<None>(float32, (False, False))]\nInputs shapes: [(1, 363), (507, 50)]\nInputs strides: [(1452, 4), (200, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Add}[(0, 0)]<gpuarray>(GpuDot22.0, InplaceGpuDimShuffle{x,0}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "'''\n",
    "main loop\n",
    "'''\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for d_step in range(d_steps):\n",
    "        \n",
    "        #train D on real data\n",
    "#         d_real_data = d_sampler(1, d_input_size)\n",
    "        d_real_data = np.expand_dims(x_train[np.random.randint(len(x_train))], axis=0)\n",
    "        d_real_targets = np.ones(1)\n",
    "        \n",
    "        #train D on fake data\n",
    "        d_gen_data = gi_sampler(1, g_input_size)\n",
    "        d_fake_data = G.model.predict(d_gen_data)\n",
    "        d_fake_targets = np.zeros(1)\n",
    "        \n",
    "        #train model\n",
    "        d_data = np.append(d_real_data, d_fake_data, axis=0)\n",
    "        d_targets = np.append(d_real_targets, d_fake_targets)\n",
    "\n",
    "        #fit discriminator\n",
    "        D.model.trainable = True\n",
    "        D.model.fit(d_data, d_targets, shuffle=True, epochs=10,\n",
    "              batch_size=1, validation_split=0.0, verbose=0)\n",
    "    \n",
    "#     print \"Completed training of D for epoch {}\".format(epoch)\n",
    "        \n",
    "    for g_step in range(g_steps):\n",
    "        \n",
    "        #generate data from noise\n",
    "        gen_input = gi_sampler(1, g_input_size)\n",
    "        \n",
    "        #target\n",
    "        target = np.ones(1)\n",
    "        \n",
    "        #fit generator\n",
    "        D.model.trainable = False\n",
    "        GD.model.fit(gen_input, target, shuffle=True, epochs=10,\n",
    "              batch_size=1, validation_split=0.0, verbose=0)\n",
    "        \n",
    "        \n",
    "#     print \"Completed training of G for epoch {}\".format(epoch)\n",
    "    \n",
    "#     print \"Epoch {} complete\".format(epoch)\n",
    "    print_progress(epoch, num_epochs, start_time)\n",
    "print \"\\nDONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.498862  ]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886236]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886698]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.498862  ]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886212]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]\n",
      " [ 0.49886194]]\n"
     ]
    }
   ],
   "source": [
    "gen_input = gi_sampler(1000, g_input_size)\n",
    "forgery = G.model.predict(gen_input)\n",
    "print D.model.predict(forgery)\n",
    "# print np.mean(forgery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_real_data = d_sampler(100, d_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.97750616,  5.25092888,  4.59791613, ...,  4.76979065,\n",
       "         4.08094931,  2.61142635],\n",
       "       [ 4.0486145 ,  4.50510311,  4.73263216, ...,  4.83788395,\n",
       "         4.6385498 ,  3.18401814],\n",
       "       [ 4.82702923,  6.47186995,  3.89000297, ...,  3.54565644,\n",
       "         5.12652969,  6.09436893],\n",
       "       ..., \n",
       "       [ 2.72764564,  4.03013802,  1.99318993, ...,  3.19162607,\n",
       "         4.72337151,  2.75904036],\n",
       "       [ 5.90803957,  1.71235585,  3.32587624, ...,  4.61864996,\n",
       "         5.31416559,  5.39929628],\n",
       "       [ 3.58024287,  3.90217638,  2.14244676, ...,  4.64943457,\n",
       "         0.63970524,  1.97230172]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
